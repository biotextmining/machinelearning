package com.silicolife.textmining.machinelearning.biotml.core.features.modules;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.TreeSet;

import com.silicolife.textmining.machinelearning.biotml.core.exception.BioTMLException;
import com.silicolife.textmining.machinelearning.biotml.core.features.datastructures.BioTMLAssociationProcess;
import com.silicolife.textmining.machinelearning.biotml.core.features.datastructures.BioTMLFeatureColumns;
import com.silicolife.textmining.machinelearning.biotml.core.interfaces.IBioTMLFeatureColumns;
import com.silicolife.textmining.machinelearning.biotml.core.interfaces.IBioTMLFeatureGenerator;
import com.silicolife.textmining.machinelearning.biotml.core.interfaces.IBioTMLFeatureGeneratorConfigurator;
import com.silicolife.textmining.machinelearning.biotml.core.nlp.stanford.BioTMLStanfordNLP;

/**
 * 
 * A class responsible for features generated by Stanford CoreNLP.
 * 
 * @since 1.0.0
 * @author Ruben Rodrigues ({@code rrodrigues@silicolife.com})
 */
public class StanfordNLPFeatures implements IBioTMLFeatureGenerator{
	
	/**
	 * 
	 * Initializes the insertion of features from StandFord Core NLP.
	 * 
	 */
	public StanfordNLPFeatures(){
	}
	
	public Set<String> getUIDs() {
		Set<String> uids = new TreeSet<String>();
		uids.add("STANFORDNLPPOS");
		uids.add("STANFORDNLPLEMMA");
		uids.add("CONJUCTSTANFORDNLPLEMMA");
		uids.add("CONJUCTSTANFORDNLPPOS");
		uids.add("WINDOWSTANFORDNLPLEMMA");
		uids.add("WINDOWSTANFORDNLPPOS");
		return uids;
	}
	
	public Set<String> getRecomendedUIDs(){
		Set<String> uids = new TreeSet<String>();
		uids.add("STANFORDNLPPOS");
		uids.add("STANFORDNLPLEMMA");
		uids.add("CONJUCTSTANFORDNLPLEMMA");
		return uids;
	}
	
	
	public Map<String, String> getUIDInfos() {
		Map<String, String> infoMap = new HashMap<>();
		infoMap.put("STANFORDNLPLEMMA", "The CoreNLP Standford lemmatization system is used to create a feature that stores the lemma of each token.");
		infoMap.put("STANFORDPOS", "The CoreNLP Standford part-of-speech system is used to create a feature that stores the POS of each token.");
		infoMap.put("CONJUCTSTANFORDNLPLEMMA", "An adaptation of conjunctions from mallet is used to create conjunctions for CoreNLP Stanford lemmatization features.");
		infoMap.put("CONJUCTSTANFORDNLPPOS", "An adaptation of conjunctions from mallet is used to create conjunctions for CoreNLP Stanford part-of-speech features.");
		infoMap.put("WINDOWSTANFORDNLPLEMMA", "An adaptation of windows from mallet is used to create 'Sliding window' for CoreNLP Stanford lemmatization features.");
		infoMap.put("WINDOWSTANFORDNLPPOS", "An adaptation of windows from mallet is used to create 'Sliding window' for CoreNLP Stanford part-of-speech features.");
		return infoMap;
	}
	
	public IBioTMLFeatureColumns getFeatureColumns(List<String> tokensToProcess,
			IBioTMLFeatureGeneratorConfigurator configuration)
			throws BioTMLException {
		
		if(tokensToProcess.isEmpty()){
			throw new BioTMLException(27);
		}
		
		BioTMLAssociationProcess tokenAnnotProcess = new BioTMLAssociationProcess(tokensToProcess);
		List<String> tokens = tokenAnnotProcess.getTokens();
		IBioTMLFeatureColumns features = new BioTMLFeatureColumns(tokens, getUIDs(), configuration);
		
		List<String> tokensPOS = null;
		List<String> tokensLemma = null;
		if(configuration.hasFeatureUID("STANFORDNLPPOS") || 
				configuration.hasFeatureUID("CONJUCTSTANFORDNLPPOS") || 
				configuration.hasFeatureUID("WINDOWSTANFORDNLPPOS")){
			tokensPOS = BioTMLStanfordNLP.getInstance().processPos(tokens);
			if(configuration.hasFeatureUID("STANFORDNLPLEMMA") ||
					configuration.hasFeatureUID("WINDOWSTANFORDNLPLEMMA") ||
					configuration.hasFeatureUID("CONJUCTSTANFORDNLPLEMMA")){
				tokensLemma = BioTMLStanfordNLP.getInstance().processLemmas(tokens, tokensPOS);
			}
		} else if(configuration.hasFeatureUID("STANFORDNLPLEMMA") ||
				configuration.hasFeatureUID("WINDOWSTANDFORNLPLEMMA") ||
				configuration.hasFeatureUID("CONJUCTSTANFORDNLPLEMMA")){
			tokensLemma = BioTMLStanfordNLP.getInstance().processLemmas(tokens, BioTMLStanfordNLP.getInstance().processPos(tokens));
		}
		
		for(int i=0; i<tokens.size(); i++){
			if(configuration.hasFeatureUID("STANFORDNLPPOS") || 
				configuration.hasFeatureUID("CONJUCTSTANFORDNLPPOS") || 
				configuration.hasFeatureUID("WINDOWSTANFORDNLPPOS")){
				tokensPOS.set(i, "STANFORDNLPPOS="+tokensPOS.get(i));
			}
			if(configuration.hasFeatureUID("STANFORDNLPLEMMA") ||
				configuration.hasFeatureUID("WINDOWSTANFORDNLPLEMMA") ||
				configuration.hasFeatureUID("CONJUCTSTANFORDNLPLEMMA")){
				tokensLemma.set(i, "STANFORDNLPLEMMA="+tokensLemma.get(i));
			}
		}
		
		features.updateTokenFeatures(tokensPOS, "STANFORDNLPPOS");
		features.updateTokenFeatures(tokensLemma, "STANFORDNLPLEMMA");
		
		if(configuration.hasFeatureUID("CONJUCTSTANFORDNLPLEMMA")){
			OffsetConjunctions conjuctions = new OffsetConjunctions(tokensLemma,  new int[][]{{-1, 0}, {-2, -1}, {0, 1}, {-1, 1}, {-3, -1}});
			features.updateTokenFeatures(conjuctions.generateFeatures(), "CONJUCTSTANFORDNLPLEMMA");
			features.setUIDhasMultiFeatureColumn("CONJUCTSTANFORDNLPLEMMA");
		}
		
		if(configuration.hasFeatureUID("CONJUCTSTANFORDNLPPOS")){
			OffsetConjunctions conjuctions = new OffsetConjunctions(tokensPOS,  new int[][]{{-1, 0}, {-2, -1}, {0, 1}, {-1, 1}, {-3, -1}});
			features.updateTokenFeatures(conjuctions.generateFeatures(), "CONJUCTSTANFORDNLPPOS");
			features.setUIDhasMultiFeatureColumn("CONJUCTSTANFORDNLPPOS");
		}
		
		if(configuration.hasFeatureUID("WINDOWSTANFORDNLPLEMMA")){
			WindowFeatures windows = new WindowFeatures("WINDOW_LEMMA=", tokensLemma, -3, 3);
			features.updateTokenFeatures(windows.generateFeatures(), "WINDOWSTANFORDNLPLEMMA");
			features.setUIDhasMultiFeatureColumn("WINDOWSTANFORDNLPLEMMA");
		}
		
		if(configuration.hasFeatureUID("WINDOWSTANFORDNLPPOS")){
			WindowFeatures windows = new WindowFeatures("WINDOW_POS=", tokensPOS, -3, 3);
			features.updateTokenFeatures(windows.generateFeatures(), "WINDOWSTANFORDNLPPOS");
			features.setUIDhasMultiFeatureColumn("WINDOWSTANFORDNLPPOS");
		}
		
		features.updateTokenFeaturesUsingAssociationProcess(tokenAnnotProcess);

		return features;
	}


	public void cleanMemory(){
		BioTMLStanfordNLP.getInstance().clearModelsInMemory();
	}

}
